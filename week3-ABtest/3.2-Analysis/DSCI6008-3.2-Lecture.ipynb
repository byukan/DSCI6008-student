{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3.2: Analysis of A/B Testing Results\n",
    "\n",
    "**Reference**: [A/B Testing - Udacity](https://www.udacity.com/course/ab-testing--ud257)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now that we've decided on the metric(s) to evaluate, chosen the sample size and run the experiment, we want to see what we can conclude / recommend from the data collected.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invariant Checking  \n",
    "\n",
    "* Before we dive into comparing the click-through probability, we need to do some sanity checks to make sure the experiment is actually run properly\n",
    "    * Something might have gone wrong in the experiment diversion, are your control and experiment groups still comparable?  \n",
    "    * Did the data capture the events you were looking for?  \n",
    "\n",
    "* We need to check if the experiment population and the control populations are actually comparable  \n",
    "* The invariants shouldn't change when you run your experiment  \n",
    "* \n",
    "**Q**: Say the metric we want to evaluate is the click-through rate, what metrics can we use for invariant checking?   \n",
    "\n",
    "**Q**: If we observed a total of 8294 pageviews in the control group and 8095 pageviews in the experiment group, how do we use it for invariant checking?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\t1-sample proportions test with continuity correction\n",
       "\n",
       "data:  8294 out of 8294 + 8095, null probability 0.5\n",
       "X-squared = 2.3921, df = 1, p-value = 0.122\n",
       "alternative hypothesis: true p is not equal to 0.5\n",
       "95 percent confidence interval:\n",
       " 0.4983857 0.5137537\n",
       "sample estimates:\n",
       "        p \n",
       "0.5060711 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can perform a Binomial/proportion test on the invariant\n",
    "prop.test(8294, 8294 + 8095)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Results for Single Metric   \n",
    "\n",
    "* We have looked at how to analyze the results for a single metric during the morning lecture  \n",
    "* Another test we might be interested in performing is the 'Sign Test'  \n",
    "\n",
    "### Sign Test\n",
    "\n",
    "* The sign test can be used if we want to furthur confirm the results, or if the metric doesn't follow any known distribution  \n",
    "\n",
    "**Example**: We run a test for one week, and obtained the daily CTR for the control and the experiment groups below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.2</li>\n",
       "\t<li>0.1</li>\n",
       "\t<li>0.22</li>\n",
       "\t<li>0.18</li>\n",
       "\t<li>0.11</li>\n",
       "\t<li>0.09</li>\n",
       "\t<li>0.09</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.2\n",
       "\\item 0.1\n",
       "\\item 0.22\n",
       "\\item 0.18\n",
       "\\item 0.11\n",
       "\\item 0.09\n",
       "\\item 0.09\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.2\n",
       "2. 0.1\n",
       "3. 0.22\n",
       "4. 0.18\n",
       "5. 0.11\n",
       "6. 0.09\n",
       "7. 0.09\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.20 0.10 0.22 0.18 0.11 0.09 0.09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ctr_cont = c(0.33, 0.45, 0.39, 0.40, 0.57, 0.63, 0.61)\n",
    "ctr_exp = c(0.53, 0.55, 0.61, 0.58, 0.68, 0.72, 0.70)\n",
    "\n",
    "# If we take the difference of the daily CTR's\n",
    "ctr_exp - ctr_cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the true CTR were the same between the two groups, what would we expect to see in terms of the signs of the differeces?   \n",
    "\n",
    "* What is the probability of observing 7 positive differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in prop.test(7, 7):\n",
      "“Chi-squared approximation may be incorrect”"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\t1-sample proportions test with continuity correction\n",
       "\n",
       "data:  7 out of 7, null probability 0.5\n",
       "X-squared = 5.1429, df = 1, p-value = 0.02334\n",
       "alternative hypothesis: true p is not equal to 0.5\n",
       "95 percent confidence interval:\n",
       " 0.5609339 1.0000000\n",
       "sample estimates:\n",
       "p \n",
       "1 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The one sample proportion test won't work too well\n",
    "# Since the sample size is too small for the Normal approximation\n",
    "prop.test(7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.015625"
      ],
      "text/latex": [
       "0.015625"
      ],
      "text/markdown": [
       "0.015625"
      ],
      "text/plain": [
       "[1] 0.015625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can calculate the p-value \n",
    "# by using the PMF/CDF of a Binomial distribution\n",
    "\n",
    "dbinom(7, 7, 0.5) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the Results for Multiple Metrics   \n",
    "\n",
    "**Q**: If we are testing 20 different metrics, and use the 95% confidence interval to make the decision on each test, what is the probability that you get at least one significant result by chance?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonferroni Correction  \n",
    "\n",
    "* The more tests we run, the more likely that we will have significant results just by chance  \n",
    "* One way to adjust for this, is to reduce the significance level of each individual test\n",
    "* The Bonferroni correction controls the familywise error rate (FWER) by rejecting the null hypothesis for all $p_i \\leq \\frac{\\alpha}{m}$, where $p_i$ is the p-value for the $i$th test, $m$ is the number of tests\n",
    "    * The familywise error rate (FWER) is the probability of rejecting at least one true $H_0$, i.e. the probability of making at least one type I error  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Discovery Rate  (FDR)    \n",
    "\n",
    "* Instead of controlling the FWER, we can also control the expected proportion of false discoveries - the FDR  \n",
    "\n",
    "$$ FDR = E \\left(\\frac{\\text{number of false positives}}{\\text{number of rejections of the } H_0} \\right)$$  \n",
    "\n",
    "* Benjamini–Hochberg procedure:\n",
    "    * Order the p-values of the $m$ tests: $p_{(1)}, p_{(2)}, \\dots, p_{(m)}$\n",
    "    * For a given $\\alpha$ , find the largest $k$ such that $p_{(k)} \\leq \\frac{k}{m} \\alpha$\n",
    "    * Reject the null hypothesis for tests, $1, 2, \\dots, k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Recommendations  \n",
    "\n",
    "* Do we have statistically and practically significant results?  \n",
    "* Do we understand the results? Do they make sense?\n",
    "* Do we want to launch the change? Is it worth it?  \n",
    "* Do we want to launch the change for a slice of the users?  \n",
    "* Do we need to run further tests?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
