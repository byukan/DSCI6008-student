{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4 Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import misc as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Amy vs. Brian\n",
    "\n",
    "Amy  has  two  coins.  The  probability  of  heads  for  the  first  coin  is  $\\dfrac{1}{3}$ the  probability  of  heads for  the  second  coin  is $\\dfrac{2}{3}$.  Other than this difference in their bias, the coins are indistinguishable.  Amy  chooses  one  of  the  coins  at random  and  gives  it to  Brian.  Let $p$  be  the  probability  that  Amy  chose  the  first  coin.  Brian  tries  to  guess  which  of  the two coins he received by  flipping it 3  times in a row and  observing  the outcome.  Assume that all coin  flips  are  independent.  Let \n",
    "$Y$ be  the observation of heads that Brian  observed. \n",
    "\n",
    "a) Given  that  Brian  observed $k$ heads,  what  is  the  probability  that  he  received  the  first  coin?\n",
    "\n",
    "b)   Find  values  of $k$ for  which  the  probability  that  Amy  sent  the  first  coin  increases  after  Brian \n",
    "observes $k$ heads  out  of  3  tosses.  In  other  words,  for  what  values  of $k$ is  the probability  that \n",
    "Amy  sent  the  first  coin  given  that  Brian  observed $k$ heads  greater  than $p$?  If  we  increase $p$, \n",
    "how does your  answer  change?\n",
    "\n",
    "c)  Help  Brian develop  the rule for deciding  which  coin he received based  on the number of heads $k$ he  observed  in  3  tosses  if  his  goal  is  to  minimize  the  probability  of  error.\n",
    "\n",
    "d) Now assume $p = 4/5$. What is the probability that Brian will guess the coin correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A)\n",
    "The probability can be written as this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(C = 1 | Y = k) = \\frac{{3 \\choose k} \\frac{1}{3}^{k} \\frac{2}{3}^{3-k}}{{3 \\choose k} \\frac{1}{3}^{k} + \\frac{2}{3}^{(3-k)} * p + {3 \\choose k} \\frac{2}{3}^{k} + \\frac{1}{3}^{(3-k)} * (1-p)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) \n",
    "We are trying to find a value if k where the following inequality holds true, given the conditional probability from above.\n",
    "\n",
    "$ P(C = 1 | Y = k) > p$\n",
    "\n",
    "$\\frac{2^{3-k}}{2^{3-k}p + 2^{k}(1-p)} > p$\n",
    "\n",
    "If p = 0 or p = 1, there is no value of k that makes this inequality true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{2^{3-k}}{2^{3-k}p + 2^{k}(1-p)} > 1$\n",
    "\n",
    "$2^{3-k} > 2^{3-k} + 2^{k}(1-p)$\n",
    "\n",
    "This can be solved for $2k < 3$, so $k < \\frac{3}{2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inequality above does not depend on p (just on k) so changing p won't change our answer. Our answer only changes with k. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) \n",
    "As the help statement stated...we need to decide when $P(C = 1 | Y = k) \\geq P(C = 2 | Y= k)$\n",
    "The first probability is $ \\frac{2^{3-k}p}{2^{3 - k}p + 2^{k}(1-p)}$ and the second is  $ \\frac{2^{k}(1-p)}{2^{3 - k}p + 2^{k}(1-p)} $ which we can then write as $ \\frac{2^{3-k}p}{2^{3 - k}p + 2^{k}(1-p)} \\geq \\frac{2^{k}(1-p)}{2^{3 - k}p + 2^{k}(1-p)} $\n",
    "\n",
    "This can be solved for k.    $k \\leq \\frac{3}{2} + \\frac{1}{2} log \\frac{p}{1-p} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Taxi Counting\n",
    "\n",
    "Consider the problem of a person summoning a taxi when standing on a street corner with an unknown probability of (A taxi is either summoned or not - i.e. binary) with success $q$. Define the arrival time $T_{k}$ between the last taxi summoned as follows:\n",
    "\n",
    "$T_{1} = Y_{1}$\n",
    "$T_{k} = Y_{k}-Y_{k-1}$\n",
    "$k=2, 3, \\ldots$\n",
    "\n",
    "Where $Y_{k}$ is the time of the $k$th success. We need to estimate $q$ based on a series of calculated arrival times: $t_{1}, t_{2}, \\ldots t_{k}$.\n",
    "\n",
    "You may find the following integral useful for this problem: \n",
    "\n",
    "$\\int_{0}^{1}q^{k}(1-q)^{m}dq = \\dfrac{m!k!}{(m+k+1)!}$\n",
    "\n",
    "You may assume that $q \\in Q$ is sampled from (belongs to some number within) the uniform distribution taken over $\\left[0,1\\right]$.\n",
    "\n",
    "a) What type of process is this?\n",
    "\n",
    "b) Calculate the probability mass function (PMF) for $T_{1}$: $p(t_{1}=t)$ You will need to integrate over $q$. You'll need to think carefully about setting up the two constants in the appropriate distribution. Specifically, what is special about the first time you make an observation? This is not as complicated of a problem as it seems. \n",
    "\n",
    "c) Compute the MMSE of $Q$ starting from $T_{1}$ Again, you will need to integrate over $q$. Use your above result.\n",
    "\n",
    "d) Compute the MAP estimate of $Q$ given $k$ recordings $T_{1} = t_{1}, T_{2} = t_{2}, \\ldots T_{k} = t_{k}$. You will need to use the chain rule to include the probability of observing each of the $k$ recordings. You will also need to use your result for b, but substitute in the appropriate time $t_{i}$ until the next observation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### A)\n",
    "The proceses represents count of the number of intervals until a success, a geometric process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: It Actually is the Economy, Stupid\n",
    "\n",
    "Predict the outcome of the 2016 Presidential Election using [this data](./election_data.txt) using a Bayesian linear regression. You are calculating the democrats' fraction of the two-party electoral vote ($VP$ or vote percentage). There are 538 electors and you need 270 to win the presidency. Train the model on features G, P, and Z. \n",
    "\n",
    "You can use these below definitions:\n",
    "\n",
    "$DPER:$ 1  if  a  Democratic  presidential  incumbent  is  running  again,-1\n",
    "if  a  Republican  presidential  incumbent  is  running  again,  and  0 otherwise.\n",
    "\n",
    "$DUR:$ 0 if either party has been in the White House for one term, 1 [-1] if\n",
    "the Democratic [Republican] party has been in the White House for\n",
    "two consecutive terms, 1.25 [-1.25] if the Democratic [Republican]\n",
    "party has been in the White House for three consecutive terms, 1.50\n",
    "[-1.50] if the Democratic [Republican] party has been in the White\n",
    "House for four consecutive terms, and so on.\n",
    "\n",
    "$WAR:$ 1 for the elections of 1918, 1920, 1942, 1944, 1946, and 1948, and\n",
    "0 otherwise.\n",
    "\n",
    "$G:$ growth rate of real per capita GDP in the first three quarters of the\n",
    "on-term election year (annual rate).\n",
    "\n",
    "$P:$ absolute value of the growth rate of the GDP deflator (growth rate of deflation) in the first 15\n",
    "quarters of the administration (annual rate) except for 1920, 1944,\n",
    "and 1948, where the values are set to zero.\n",
    "\n",
    "$Z:$ number of quarters in the first 15 quarters of the administration in\n",
    "which the growth rate of real per capita GDP is greater than 3.2\n",
    "percent at an annual rate except for 1920, 1944, and 1948, where\n",
    "the values are zero.\n",
    "\n",
    "These are the data for the [forward predictions](./prediction.txt). \n",
    "\n",
    "**HINT:** My calculations showed in October that HRC should have had 236 electoral votes. Her final count was 232.\n",
    "\n",
    "Write a short nonpartisan paragraph speculating as to the underlying reason why this analysis works.\n",
    "\n",
    "#### Advanced:\n",
    "\n",
    "1. Estimates of variance for $\\boldsymbol \\Lambda_{0}$ can be obtained from an analysis of the data. Calculate the MAP estimate using these. \n",
    "\n",
    "2. Using simulations, calculate and plot the 95% credible envelopes for the estimate of the winner for the Presidential election. From this, produce an analysis\n",
    "\n",
    "3. Try using another model that will accept the categorical data. Do they help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to do this problem in two different ways, using SKLEARN and using PYMC3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table('./election_data.txt',delim_whitespace = True)\n",
    "df1 = df.ix[1:]\n",
    "df1['P'] = pd.to_numeric(df1['P'])\n",
    "df1['Z'] = pd.to_numeric(df1['Z'])\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df1[['G', 'P','Z']].values\n",
    "Y = df1[['VP']].values\n",
    "#Add a column of ones for the intercept\n",
    "X = np.concatenate((np.ones((X.shape[0], 1), dtype = X.dtype), X), axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf = BayesianRidge(compute_score=True)\n",
    "clf.fit(X, Y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_data = pd.read_table('./prediction.txt', delim_whitespace = True)\n",
    "X_pred = pred_data[['G', 'P','Z']].values\n",
    "#again, add a column of ones\n",
    "X_pred = np.concatenate((np.ones((X_pred.shape[0], 1), dtype = X_pred.dtype), X_pred), axis = 1)\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of electoral college votes the Democratic candidate will given the data on each date in the prediction file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_probs = clf.predict(X_pred)\n",
    "(dem_probs/100) * 538"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find a value of approximately 263"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the model with PYMC3 and the Generalized Linear Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "from pymc3.glm import glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "niters = 10000\n",
    "with Model() as model_glm:\n",
    "    glm('VP ~ G + Z + P', df1)  # specify the model (utilizes Patsy so the model specification ressembles R)\n",
    "    start = pm.find_MAP()       #estimate the initial values using MAP\n",
    "    step = pm.NUTS()            #an optimized MCMC method for better convergence\n",
    "    trace = sample(niters, step, start, random_seed=12, progressbar = True)\n",
    "    pm.traceplot(trace)         #plot the posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the model (same as above, but in more tabular form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I attempted to determine how to predict using all the data in the prediction file, but was only able to predict one data set at a time.\n",
    "\n",
    "For the October data I get the following values which are still below 270, but slightly above that from the SKLEARN implementation. However, the SKLEARN implementation is performing Ridge Regression and the GLM from pymc3 is not (though it potentially could)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = 0.97    \n",
    "Z = 2\n",
    "P = 1.42\n",
    "VP = (0.297 * G) + (-0.162 * Z) + (0.0 * P) + 49.563\n",
    "(VP/100) * 538"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of these values predict 236 or 232. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
