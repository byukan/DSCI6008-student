{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chirps = [20., 16., 19.8, 18.4, 17.1, 15.5,14.7,17.1,15.4,16.2, 15., 17.2, 16., 17., 14.1]\n",
    "temp = [88.6, 71.6, 93.3, 84.3, 80.6, 75.2, 69.7, 82., 69.4, 83.3, 78.6, 82.6, 80.6, 83.5, 76.3]\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "%matplotlib inline\n",
    "\n",
    "# now try to predict chirps with temp\n",
    "\n",
    "plt.scatter(temp, chirps)\n",
    "x = np.expand_dims(chirps,axis=1)\n",
    "ones = np.ones(shape=(len(chirps),1))\n",
    "X = np.hstack((ones,x)) #this is your design matrix\n",
    "n = X.shape[0]\n",
    "k = X.shape[1]\n",
    "y = np.expand_dims(temp, axis=1)\n",
    "\n",
    "Q, R = np.linalg.qr(X)\n",
    "RInv = np.linalg.inv(R)\n",
    "RtInv = np.linalg.inv(R.T)\n",
    "V_beta = RInv.dot(RtInv)\n",
    "Beta_hat = RInv.dot(Q.T.dot(y))\n",
    "df = n-k \n",
    "e=y-X.dot(Beta_hat) # error vector = difference in predictions\n",
    "s2 = np.sum(e.T.dot(e))/df # sum of squared errors!\n",
    "\n",
    "# Now we produce a simulation of the posterior values of the weights\n",
    "\n",
    "n_sims = 100000\n",
    "sigma = np.reshape(np.sqrt(st.invgamma.rvs(a=df/2.,scale=1./(df*s2/2.), size=n_sims)),(-1,1))\n",
    "B_sims = np.repeat(Beta_hat.T,n_sims,axis=0)+sigma*np.random.multivariate_normal(mean=np.zeros(2),cov=V_beta,size=(n_sims,))\n",
    "print(Beta_hat)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_nlp]",
   "language": "python",
   "name": "conda-env-py3_nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
