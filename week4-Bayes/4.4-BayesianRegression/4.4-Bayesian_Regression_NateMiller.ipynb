{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 6008 4.4 Bayesian Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the past, you have learned linear regression based on the ML estimate, this being the traditional Moore-Penrose pseudoinverse:\n",
    "\n",
    "$$\\hat{\\beta} = ({\\bf{X^{T}X}})^{-1}{\\bf{X^{T}y}}$$\n",
    "\n",
    "However, as you well know the OLS estimate is prone to overfitting. \n",
    "Supppose you needed to make an investment decision based on a linear regression but needed to weight the amount of money you intend to invest based on your uncertainty in the estimate (this is standard). In this case you will need to some create a MAP estimate for your regression, and here we enter bayesian regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian regression\n",
    "\n",
    "\n",
    "Suppose you are attempting to model a linear signal $y$ s.t.\n",
    "\n",
    "$$y = \\beta{\\bf{x}} + {\\bf{e}}$$\n",
    "\n",
    "This is the familiar regression model. However, in this case, we will consider the idea that the error vector ${\\bf{e}}$ is a gaussian distribution with a mean around 0. Note that the variance term $\\sigma^{2}$ is a covariance matrix:\n",
    "\n",
    "$${\\bf{e}} \\sim N(0, \\sigma^{2})$$\n",
    "\n",
    "By now we have covered enough of these problems so that you should recognize how to form the posterior for this problem:\n",
    "\n",
    "$$p(y |\\ {\\bf{x}}, \\beta, \\sigma^{2}) \\sim N({\\beta\\bf{x}}, \\sigma^{2})$$\n",
    "\n",
    "This is a response signal with a linear mean and a variance of magnitude $\\sigma$. Now we consider the collection of data $Y=y_{i}$ paired with $X=x_{i}$, so as to make a reorderable collection of pairs $(y_{i},x_{i})$ \n",
    "\n",
    "$$p({\\bf{Y}} |\\ {\\bf{X}}, \\beta, V) = \\Pi_{i}p(y_{i}|\\ x_{i},\\beta,\\sigma^{2})$$\n",
    "\n",
    "Note that this is the product of independent probabilities. We can reform this equation in matrix form:\n",
    "\n",
    "\n",
    "$$ = \\dfrac{1}{(\\sigma^{2})^{\\frac{N}{2}}}\\text{exp}\\left(-\\frac{1}{2\\sigma^{2}}({\\bf{Y}}-\\beta{\\bf{X}})({\\bf{Y}}-\\beta{\\bf{X}})^{T}\\right) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formation of the conjugate prior: The matrix-normal density\n",
    "\n",
    "Right now, our information about $\\beta$ is really vague. Rewriting an estimator for the term inside the exponential function above using the OLS (Moore-Penrose) pseudoinverse:\n",
    "\n",
    "$$\\hat{\\beta} = ({\\bf{X^{T}X}})^{-1}{\\bf{X^{T}y}}$$\n",
    "\n",
    "gives us the following expansion which is normal with respect to the error in estimate for $\\beta$, $(\\beta-\\hat{\\beta})$:\n",
    "\n",
    "$$({\\bf{Y}}-\\beta{\\bf{X}})({\\bf{Y}}-\\beta{\\bf{X}})^{T} = ({\\bf{y-\\hat{\\beta}X}})^{T}({\\bf{y-\\hat{\\beta}X}})+(\\beta-\\hat{\\beta})^{T}({\\bf{X^{T}X}})(\\beta-\\hat{\\beta})$$\n",
    "\n",
    "Now we can rewrite the likelihood:\n",
    "\n",
    "$$p({\\bf{y}}|{\\bf{X}},\\beta,\\sigma^{2}) \\propto (\\sigma^2)^{-\\frac{v}{2}} \\exp\\left(-\\frac{vs^{2}}{2{\\sigma}^{2}}\\right)(\\sigma^2)^{-\\frac{n-v}{2}} \\exp\\left(-\\frac{1}{2{\\sigma}^{2}}(\\beta - \\hat{\\beta})^{\\rm T}({\\bf{X}}^{T}{\\bf{X}})(\\beta - \\hat{\\beta})\\right)$$\n",
    "\n",
    "Given that\n",
    "\n",
    "$$vs^{2} =(\\mathbf{y}- \\hat{\\beta}\\mathbf{X} )^{\\rm T}(\\mathbf{y}- \\hat{\\beta}\\mathbf{X} ) \\quad  \\text{ and } \\quad v = n-k$$\n",
    "\n",
    "where $k$ is the number of regression coefficients.\n",
    "\n",
    "\n",
    "This suggests a form for the prior:\n",
    "\n",
    "$$p(\\beta,\\sigma^{2}) = p(\\beta|\\sigma^{2})p(\\sigma^{2})$$\n",
    "\n",
    "The conditional prior must be matrix-normal:\n",
    "\n",
    "$$p(\\beta|\\sigma^{2}) \\propto (\\sigma^2)^{-\\frac{k}{2}} \\exp\\left(-\\frac{1}{2{\\sigma}^{2}}(\\beta - \\mu_0)^{\\rm T} \\mathbf{\\Lambda}_0 (\\beta - \\mu_0)\\right)$$\n",
    "\n",
    "Where the $\\Lambda_{0}$ is a matrix of variance magnitudes (what does this remind you of)\n",
    "\n",
    "And $p(\\sigma^{2})$ is an [inverse gamma distribution](https://en.wikipedia.org/wiki/Inverse-gamma_distribution):\n",
    "\n",
    "$$p(\\sigma^{2}) \\propto \\dfrac{1}{(\\sigma^2)^{\\frac{v_{0}}{2}+1}} \\exp\\left(-\\frac{v_{0}s_{0}^{2}}{2{\\sigma}^{2}}\\right)$$\n",
    "\n",
    "In simple notation, we'd write this as the matrix normal: $N(\\mu_{0}, \\sigma^{2}\\Lambda_{0}^{-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of the Posterior (Evidence) for the model\n",
    "\n",
    "Using the simplifications:\n",
    "\n",
    "$a_0=\\tfrac{v_0}{2}$ and $b_0=\\tfrac{1}{2}v_0s_0^2 $ with $v_{0}$ and $s_{0}^{2}$ as the prior values of $v$ and $s^{2}$, respectively. We can write the posterior as follows:\n",
    "\n",
    "$$p(\\beta,\\sigma^{2}|\\mathbf{y},\\mathbf{X}) \\propto p(\\mathbf{y}|\\mathbf{X},\\beta,\\sigma^{2})p(\\beta|\\sigma^{2})p(\\sigma^{2}) $$\n",
    "\n",
    "$$\\propto \\dfrac{1}{(\\sigma^{2})^{\\frac{n}{2}}}\\exp\\left(-\\frac{1}{2{\\sigma}^{2}}(\\mathbf{y}- \\mathbf{X}\\beta)^{\\rm T}(\\mathbf{y}- \\mathbf{X}\\beta)\\right) \\dfrac{1}{(\\sigma^{2})^{\\frac{k}{2}}}\\exp\\left(-\\frac{1}{2{\\sigma}^{2}}(\\beta -\\mu_0)^{\\rm T} \\boldsymbol\\Lambda_0 (\\beta - \\mu_0)\\right)  \\dfrac{1}{(\\sigma^2)^{a_0+1}} \\exp\\left(-\\frac{b_0}{{\\sigma}^{2}}\\right)$$\n",
    "\n",
    "With some re-arrangement, the posterior can be re-written so that the posterior mean $\\mu_n$ of the parameter vector $\\beta$ can be expressed in terms of the least squares estimator $\\hat{\\beta}$ and the prior **coefficient** mean $\\mu_0$, with the strength of the prior indicated by the prior matrix of variances $\\Lambda_0$\n",
    "\n",
    "To justify that $\\mu_n$ is indeed the posterior **coefficient** mean, the quadratic terms in the exponential can be re-arranged in [quadratic form](https://en.wikipedia.org/wiki/Quadratic_form) about $\\beta-\\mu_n$.\n",
    "\n",
    "$(\\mathbf{y}- \\mathbf{X} \\beta)^{\\rm T}(\\mathbf{y}- \\mathbf{X} \\beta) + (\\beta - \\mu_0)^{\\rm T}\\boldsymbol\\Lambda_0(\\beta - \\mu_0) =(\\beta - \\mu_n)^{\\rm T}(\\mathbf{X}^{\\rm T}\\mathbf{X}+\\boldsymbol\\Lambda_0)(\\beta - \\mu_n)+\\mathbf{y}^{\\rm T}\\mathbf{y}-\\mu_n^{\\rm T}(\\mathbf{X}^{\\rm T}\\mathbf{X}+\\boldsymbol\\Lambda_0)\\mu_n+\\mu_0^{\\rm T}\\boldsymbol\\Lambda_0\\mu_0$\n",
    "\n",
    "Now we can rewrite the posterior as a normal multiplied by an inverse-gamma distribution with different coefficients:\n",
    "\n",
    "$p(\\beta,\\sigma^{2}|\\mathbf{y},\\mathbf{X}) \\propto \\dfrac{1}{(\\sigma^2)^{\\frac{k}{2}}}\\exp\\left(-\\dfrac{1}{2{\\sigma}^{2}}(\\beta - \\mu_n)^{\\rm T}(\\mathbf{X}^{\\rm T}\\mathbf{X}+\\mathbf{\\Lambda}_0)(\\beta - \\mu_n)\\right) \\dfrac{1}{(\\sigma^2)^{\\frac{n+2a_{0}}{2}+1}}\\exp\\left(-\\dfrac{2 b_0+\\mathbf{y}^{\\rm T}\\mathbf{y}-\\mu_n^{\\rm T}(\\mathbf{X}^{\\rm T}\\mathbf{X}+\\boldsymbol\\Lambda_0)\\mu_n+\\mu_0^{\\rm T}\\boldsymbol\\Lambda_0\\mu_0}{2{\\sigma}^{2}}\\right)$\n",
    "\n",
    "This can be interpreted as Bayesian learning where the parameters are updated according to the following equations.\n",
    "\n",
    "$ \\mu_n=(\\mathbf{X}^{\\rm T}\\mathbf{X}+\\boldsymbol\\Lambda_0)^{-1} (\\boldsymbol\\Lambda_0\\mu_0+\\mathbf{X}^{\\rm T}\\mathbf{X}\\hat{\\beta})=(\\mathbf{X}^{\\rm T}\\mathbf{X}+\\boldsymbol\\Lambda_0)^{-1} (\\boldsymbol\\Lambda_0\\mu_0+\\mathbf{X}^{\\rm T}\\mathbf{y})$\n",
    "\n",
    "$\\boldsymbol\\Lambda_n=(\\mathbf{X}^{\\rm T}\\mathbf{X}+\\boldsymbol\\Lambda_0)$\n",
    "\n",
    "$a_n= a_0 + \\frac{n}{2}$\n",
    "\n",
    "$b_n= b_0 + \\frac{1}{2}(\\mathbf{y}^{\\rm T}\\mathbf{y}+\\mu_0^{\\rm T}\\boldsymbol\\Lambda_0\\mu_0-\\mu_n^{\\rm T}\\boldsymbol\\Lambda_n\\mu_n) $\n",
    "\n",
    "These can be solved with Bayesian updating.\n",
    "\n",
    "The special case $\\mu_0=0$, $\\mathbf{\\Lambda}_0 = c\\mathbf{I}$ is called [(Bayesian) ridge regression](https://en.wikipedia.org/wiki/Tikhonov_regularization). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing a solution to the above math\n",
    "\n",
    "\n",
    "It's not difficult to see that the above model is difficult to interpret for the purpose of writing an optimization, so we are going to make some substitutions at this point to reduce the pain of finding an actual solution with a computer.\n",
    "\n",
    "There are a few different ways of getting clear solutions. \n",
    "\n",
    "### The de facto MAP estimate\n",
    "\n",
    "For simple cases, we can make a computation directly that closely resembles the OLS estimate of $\\hat{\\beta}$.\n",
    "\n",
    "Starting with an *a priori* estimate of $\\boldsymbol \\Lambda_{0}$ (this is a diagonal matrix with the inverse of each $\\lambda_{0}^{i}$ positioned on the diagonal) and $\\sigma^{2}$, we can construct the posterior directly:\n",
    "\n",
    "$\\boldsymbol \\Lambda_{0} = \\begin{bmatrix}\n",
    "                    \\frac{1}{\\lambda_{1}} & 0 & \\cdots & 0 \\\\ \n",
    "                    0 & \\frac{1}{\\lambda_{2}} & \\cdots & 0 \\\\\n",
    "\\vdots & \\cdots & \\cdots & \\cdots \\\\\n",
    "0 & 0 & \\cdots & \\frac{1}{\\lambda_{n}}\n",
    "                    \\end{bmatrix}$\n",
    "\n",
    "\n",
    "$\\beta_{0} = \\sigma^{2}\\boldsymbol\\Lambda_{0}\\mu_{0}$\n",
    "\n",
    "An estimate of beta is formed from the above equations\n",
    "\n",
    "$\\hat{\\beta_{n}} = \\mu_{n} = (\\mathbf{X}^{\\rm T}\\mathbf{X}+\\sigma^{2}\\boldsymbol\\Lambda_{0})^{-1}(\\mathbf{X}^{\\rm T}\\mathbf{y}+\\beta_{0})$\n",
    "\n",
    "To make a prediction $\\hat{y}$, we just use the math above:\n",
    "\n",
    "$\\hat{y} = \\boldsymbol X \\hat{\\beta_{n}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Objective Estimate\n",
    "\n",
    "In professional settings, the above estimate is not often computed, and rather a computationally simpler method is used altogether.\n",
    "\n",
    "We instead make the following simplifications. First recalling back to your linear algebra, it should be obvious to you that $\\boldsymbol \\Lambda_{0}$ is a description of variance. It should also be further understood that the observed quantities ${\\bf{X}}$  (the actual data) are actually the **posterior**. We can estimate these with a QR decomposition:\n",
    "\n",
    "${\\bf X} = {\\bf QR}$\n",
    "\n",
    "$({\\bf{X}^{\\rm T}X} + \\sigma^{2} \\boldsymbol \\Lambda_{0})^{-1} \\sim ({\\bf{X}^{\\rm T}X})^{-1} = ({\\bf{QR}^{\\rm T}QR})^{-1} = ({\\bf{R}^{\\rm T}{Q}^{\\rm T}QR})^{-1} = ({\\bf{R}^{\\rm T}R})^{-1} = {\\bf R}^{\\rm -1}(\\bf R^{\\rm T})^{-1} $\n",
    "\n",
    "$(\\mathbf{X}^{\\rm T}\\mathbf{y}+\\beta_{0}) \\sim \\mathbf{X}^{\\rm T}\\mathbf{y} = {\\bf R^{\\rm T}Q^{\\rm T}}\\bf y$\n",
    "\n",
    "\n",
    "$\\hat{\\beta_{n}} = \\mu_{n} = (\\mathbf{X}^{\\rm T}\\mathbf{X}+\\sigma^{2}\\boldsymbol\\Lambda_{0})^{-1}(\\mathbf{X}^{\\rm T}\\mathbf{y}+\\beta_{0}) ={\\bf R^{-1}Q^{\\rm T}y}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 26.01204318]\n",
      " [  3.24416574]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKpxBLkmFM8glqXD/Dyw5dxsdrJk1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112611990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chirps = [20., 16., 19.8, 18.4, 17.1, 15.5,14.7,17.1,15.4,16.2, 15., 17.2, 16., 17., 14.1]\n",
    "temp = [88.6, 71.6, 93.3, 84.3, 80.6, 75.2, 69.7, 82., 69.4, 83.3, 78.6, 82.6, 80.6, 83.5, 76.3]\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "%matplotlib inline\n",
    "\n",
    "# now try to predict chirps with temp\n",
    "\n",
    "plt.scatter(temp, chirps)\n",
    "x = np.expand_dims(chirps,axis=1)\n",
    "ones = np.ones(shape=(len(chirps),1))\n",
    "X = np.hstack((ones,x)) #this is your design matrix\n",
    "n = X.shape[0]\n",
    "k = X.shape[1]\n",
    "y = np.expand_dims(temp, axis=1)\n",
    "\n",
    "Q, R = np.linalg.qr(X)\n",
    "RInv = np.linalg.inv(R)\n",
    "RtInv = np.linalg.inv(R.T)\n",
    "V_beta = RInv.dot(RtInv)\n",
    "Beta_hat = RInv.dot(Q.T.dot(y))\n",
    "df = n-k \n",
    "e=y-X.dot(Beta_hat) # error vector = difference in predictions\n",
    "s2 = np.sum(e.T.dot(e))/df # sum of squared errors!\n",
    "\n",
    "# Now we produce a simulation of the posterior values of the weights\n",
    "\n",
    "n_sims = 100000\n",
    "sigma = np.reshape(np.sqrt(st.invgamma.rvs(a=df/2.,scale=1./(df*s2/2.), size=n_sims)),(-1,1))\n",
    "B_sims = np.repeat(Beta_hat.T,n_sims,axis=0)+sigma*np.random.multivariate_normal(mean=np.zeros(2),cov=V_beta,size=(n_sims,))\n",
    "print(Beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSY0z6CWpcf8PFQbA2seHE7kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1117a4250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "B0_hist = plt.hist((B_sims[:,0]),bins=100,normed=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2NzyXvAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1120ce590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "B1_hist = plt.hist((B_sims[:,1]),bins=100,normed=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, these estimates can be used to predict credibility intervals for the values of $\\beta$, and can also be used to create credibility envelopes for the the prediction (by taking the values at the edges of the credibility and using these to plot the edges of the envelope)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other types of regressions - \n",
    "\n",
    "There are literally dozens of types of regressions that use a MAP estimate but different types of models of noise and stochasiticity in variables. These fall under the aegis of **Generalized Linear Models**. We will consider these later."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
