{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 6008 4.2 Bayesian Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate Priors:\n",
    "\n",
    "Thinking about trying to make a prediction of an event $x$ using a set of parameters $\\theta$, we might write Bayes' law:\n",
    "\n",
    "$$p(\\theta\\ |\\ x) = \\dfrac{p(x\\ |\\ \\theta)p(\\theta)}{p(x)}$$\n",
    "\n",
    "if we are trying to find the set of parameters that best predicts our outcome space. Making a choice of prior often hinges on the nontrivial requirement that the posterior is **normalizable** over a continuous distribution.\n",
    "\n",
    "In all predictive modeling, note that the future prediction of $x$ and thus the posterior, is based on prior probability:\n",
    "\n",
    "$$p(x_{new} | x_{old}) = \\int p(x_{new}\\ |\\theta)p(\\theta| x_{old})d\\theta$$\n",
    "\n",
    "However, making an effective choice of prior often hinges on the nontrivial requirement that the posterior is **normalizable** over a continuous distribution:\n",
    "\n",
    "$$p(x) = \\int p(x_{old}\\ |\\theta)p(\\theta)d\\theta$$\n",
    "\n",
    "Hence computing the inferred posterior:\n",
    "\n",
    "$$p(\\theta\\ |\\ x_{old}) = \\dfrac{p(x\\ |\\ \\theta)p(\\theta)}{\\int p(x_{old}\\ |\\theta)p(\\theta)d\\theta}$$\n",
    "\n",
    "\n",
    "This is a matter of practical mathematics as well as conceptual design.\n",
    "Trying to find something that integrates cleanly without simply compounding the problems inherent in the above integral is a challenge usually glossed over by most sources. \n",
    "\n",
    "Here let us introduce the notion of a **conjugate prior**. The basic idea is that we choose a prior belonging to a family of functions whose integrals can easily be evaluated. In addition, the **conjugate prior** needs to yield an integral that is also in the same family. This makes the process of bayesian (prior-to-posterior) updating smooth and reliable. For computationally difficult problems, the selection of a conjugate prior may be the only real choice. \n",
    "\n",
    "### Choosing the Conjugate prior\n",
    "\n",
    "This is typically done by examining the form of the distribution you are trying to model and choosing a function that can produce an integral of the same form.\n",
    "\n",
    "### The Beta-Bernoulli Conjugation\n",
    "\n",
    "Let's choose a conjugate prior for the coin flip example:\n",
    "\n",
    "We know that the likelihood for the coin flip ought to be something of the form:\n",
    "\n",
    "$$L(S) = p_{heads}^{m}(1-p_{heads})^{n-m}$$\n",
    "\n",
    "The prior for this should be of the same form, as we expect the coin to have a history commensurate to the likelihood. Assume that the prior has the form:\n",
    "\n",
    "$$q^{\\alpha}(1-q)^{\\beta}$$\n",
    "\n",
    "So the posterior after $s$ trials should be of the form:\n",
    "\n",
    "$$q^{\\alpha+f(s)}(1-q)^{\\beta+g(s)}$$\n",
    "\n",
    "Where $f$ and $g$ are simple functions of s. This is the conjugate prior that we are looking for. \n",
    "\n",
    "Let's expand this discussion:\n",
    "\n",
    "Choose the likelihood to be a Bernoulli variable. This is characterized by a Binomial distribution. The probability of $m$ successes and $n-m$ failures with this particular coin $(q = x)$ is:\n",
    "\n",
    "$$p(m,n|q=x) = {{n}\\choose{m}}x^{m}(1-x)^{n-m}$$\n",
    "\n",
    "Let's choose a prior for this coin:\n",
    "\n",
    "$$p(q=x) = \\dfrac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\beta)}$$\n",
    "\n",
    "Where the function $B$ is defined:\n",
    "\n",
    "$$B(\\alpha,\\beta) = \\int_{0}^{1}x^{\\alpha-1}(1-x)^{\\beta-1}dx$$\n",
    "\n",
    "Note that two of the three pieces of Bayes' equation are in place; we have p(m|q=x) (the likelihood) and p(q=x) (the prior). Now we calculate:\n",
    "\n",
    "$$p(q=x|m,n) = \\dfrac{p(m,n|x)p(x)}{\\int p(m,n|x)p(x)dx}$$\n",
    "\n",
    "$$ = \\dfrac{{{n}\\choose{m}}x^{m}(1-x)^{n-m}\\left[\\dfrac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\beta)}\\right]}{\\int_0^{x} {{n}\\choose{m}}y^{m}(1-y)^{n-m}\\left[\\dfrac{y^{\\alpha-1}(1-y)^{\\beta-1}}{B(\\alpha,\\beta)}\\right]dy} $$\n",
    "\n",
    "$$ = \\dfrac{x^{m+\\alpha-1}(1-x)^{n-m+\\beta-1}}{\\int_0^{x} y^{m+\\alpha-1}(1-y)^{n-m+\\beta-1}dy} $$\n",
    "\n",
    "$$ = \\dfrac{x^{m+\\alpha-1}(1-x)^{n-m+\\beta-1}}{B(m+\\alpha,n-m+\\beta)} $$\n",
    "\n",
    "As you can see the **posterior** is simply the **prior** with changes to the hyperparameters. This is the **conjugate** prior. We can get the **conjugate** prior for any set of functions which have a closed integral by completing the above Bayesian integral with the chosen likelihood function. Again, the denominator integral (called the **partition function**) has to be closed and evaluate cleanly to the prior. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptions to using a Conjugate prior\n",
    "\n",
    "As convenient as conjugate priors are, there may be good reasons not to use them. The subjectivist Bayesian may consider the choice of prior a good opportunity to express knowledge about the system, and thus provide relief from inconvenient data, *minimizing* impact of the data on the estimate. If one is an objectivist Bayesian however, the choice of a prior is making a-priori assumptions about the data before it is collected, and creates a *maximum* impact on the collected data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The posterior predictive\n",
    "\n",
    "The **posterior predictive distribution** is significantly more interesting than the posterior. The posterior predictive actually tells us the expected distribution of the data that we have *not yet observed*.\n",
    "\n",
    "Recall that for a fixed value of a parameter (or parameter set) $\\theta$, our data $X$ will follow the distribution $p(X|\\theta)$ given that we have chosen $p(X|\\theta)$ correctly. In fact, given this value of $\\theta$ we can predict the expected distribution of $X$. Now suppose that we want to understand what our forward prediction of $X$ ought to be. In order to do so, we need to assume that we don't have an exact measurement of $\\theta$; what we can do is average over all possible values of $\\theta$. This is called *marginalizing* out the parameters. (note that this is done mathematically before we get a machine involved)\n",
    "\n",
    "Thus the **prior predictive distribution** for a new value of data $x_{new}$ before taking a sample is found:\n",
    "\n",
    "$$p(x_{new}) = \\int_{\\theta}p(x_{new}|\\theta)p(\\theta)d\\theta$$\n",
    "\n",
    "(this is rarely used)\n",
    "\n",
    "After new data is observed we can discuss the **posterior** in the context of the new data:\n",
    "\n",
    "$$p(x_{new}|{\\bf{x}}) = \\int_{\\theta}p(x_{new}|\\theta, {\\bf{x}})p(\\theta, {\\bf{x}})d\\theta$$\n",
    "\n",
    "This is a prediction of how we expect **new data** to behave given our last measurement.\n",
    "\n",
    "Posterior predictives are difficult to evaluate, even for the best behaved set of distributions. You are best off just remembering how they are gotten, choosing an appropriate prior and conjugate and referring to a table. Even if we choose ideally simple distributions, the posterior predictive can be very difficult to evaluate.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "As a very simple example, we can compute the posterior predictive of the Bernoulli function. Below I am using 1 vs. 0 rather than Heads vs. Tails, but you can think of it as the same thing. \n",
    "\n",
    "The prior predictive is as follows:\n",
    "\n",
    "$$p(x) = \\int_{0}^{1} {{n}\\choose{x}} \\theta^{m}(1-\\theta)^{n-m}d\\theta = \\dfrac{1}{n+1} $$\n",
    "\n",
    "For the posterior predictive, we can integrate it in symbolic form:\n",
    "\n",
    "$$p(x_{new} = 1|x) = \\int_{0}^{1}p(x_{new} = 1|\\theta, {\\bf{x}})p(\\theta|x)d\\theta$$\n",
    "\n",
    "The in this case, it just so happens that $p(x_{new} = 1|\\theta, {\\bf{x}}) = \\theta$, the parameter for frequency of positive values:\n",
    "\n",
    "$$p(x_{new} = 1|x) = \\int_{0}^{1}\\theta\\ p(\\theta|x)d\\theta$$\n",
    "\n",
    "Now you can see that this is simply the expectation value of $p(\\theta|x) = E(\\theta|x)$. In this particular case, we are calculating the average of the Bernoulli distribution parameter $\\theta$ given the current set of data. This is simply the average number of times we have observed 1:\n",
    "\n",
    "$$E(\\theta\\ |\\ x) = \\dfrac{x+1}{n+2}$$\n",
    "\n",
    "More complex close form posterior predictives are troublesome and often require the use of gamma functions. More often, a Monte Carlo integration(to be covered in later lectures) can be used to obtain the posterior predictive with good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posterior predictives from normalization\n",
    "\n",
    "In general, the posterior predictives can be also be computed from the **normalization** point of view. Consider the following:\n",
    "\n",
    "The conjugate prior of the Bernoulli can be written (with positive outcome parameter $\\theta$) as follows\n",
    "\n",
    "$$p(\\theta\\ |\\ \\alpha) = K(\\alpha)\\theta^{\\alpha_{1}-1}(1-\\theta)^{\\alpha_{2}-1}$$\n",
    "\n",
    "Here the distribution is parameterized with $\\alpha_{1}-1$ instead of $m$. The normalization function is as above the Beta distribution:\n",
    "\n",
    "$$ K(\\alpha) = \\left(\\int_{\\theta}\\theta^{\\alpha_{1}-1}(1-\\theta)^{\\alpha_{2}-1}\\ d\\theta \\right)^{-1} $$\n",
    "\n",
    "$$ K(\\alpha) = \\dfrac{\\Gamma(\\alpha_{1}+\\alpha_{2})}{\\Gamma(\\alpha_{1})\\Gamma(\\alpha_{2})}$$\n",
    "\n",
    "The fact that the normalization factor of the beta distribution has a closed analytic form allows us to compute various averages in closed form.\n",
    "\n",
    "The **posterior predictive** can be calculated by looking at the posterior expectation value:\n",
    "\n",
    "$$ E\\left[\\theta\\ |\\ \\alpha\\right] = \\int \\theta\\ K(\\alpha)\\theta^{\\alpha_{1}-1}(1-\\theta)^{\\alpha_{2}-1}d\\theta $$\n",
    "\n",
    "$$ = \\int  K(\\alpha)\\theta^{\\alpha_{1}}(1-\\theta)^{\\alpha_{2}-1}d\\theta $$\n",
    "\n",
    "$$ = \\dfrac{\\Gamma(\\alpha_{1}+\\alpha_{2})\\Gamma(\\alpha_{1}+1)\\Gamma(\\alpha_{2})}{\\Gamma(\\alpha_{1})\\Gamma(\\alpha_{2})\\Gamma(\\alpha_{1}+\\alpha_{2}+1)} $$\n",
    "\n",
    "We can use the open definition of $\\Gamma$, $\\Gamma(n) = (n-1)!$ to do some simplification:\n",
    "\n",
    "$$ = \\dfrac{\\Gamma(\\alpha_{1}+\\alpha_{2})\\Gamma(\\alpha_{1}+1)}{\\Gamma(\\alpha_{1}) \\Gamma(\\alpha_{1}+\\alpha_{2}+1)} $$\n",
    "\n",
    "\n",
    "$$ = \\dfrac{(\\alpha_{1}+\\alpha_{2}-1)!(\\alpha_{1})!}{(\\alpha_{1}-1)!(\\alpha_{1}+\\alpha_{2})!} $$\n",
    "\n",
    "$$ = \\dfrac{(\\alpha_{1})!}{(\\alpha_{1}-1)!(\\alpha_{1}+\\alpha_{2})} $$\n",
    "\n",
    "$$ = \\dfrac{\\alpha_{1}}{\\alpha_{1}+\\alpha_{2}} $$\n",
    "\n",
    "Applying this prior mean with the posterior predictive hyperparameter updates, we have an exact figure for the posterior predictive mean!!!:\n",
    "\n",
    "$$ E\\left[\\theta\\ |\\ {\\bf{x}}, \\alpha\\right] = \\dfrac{\\sum_{n=1}^{N}x_{n}+\\alpha_{1}}{N+\\alpha_{1}+\\alpha_{2}}$$\n",
    "\n",
    "The variance can be obtained in the same way (left for you as an exercise):\n",
    "\n",
    "$$ Var\\left[\\theta\\ |\\ {\\bf{x}}, \\alpha\\right] = \\dfrac{(\\sum_{n=1}^{N}x_{n}+\\alpha_{1})(N-\\sum_{n=1}^{N}x_{n}+\\alpha_{2})}{(N+\\alpha_{1}+\\alpha_{2}+1)(N+\\alpha_{1}+\\alpha_{2})^{2}}$$\n",
    "\n",
    "if you take the limit of these values as $N \\rightarrow \\infty$\n",
    "\n",
    "$$ \\lim_{N \\rightarrow \\infty}E\\left[\\theta\\ |\\ {\\bf{x}}, \\alpha\\right] = \\dfrac{1}{N}\\sum_{n=1}^{N}x_{n}$$\n",
    "\n",
    "$$ \\lim_{N \\rightarrow \\infty}Var\\left[\\theta\\ |\\ {\\bf{x}}, \\alpha\\right] = 0$$\n",
    "\n",
    "We can see where Bayesian statistics and frequentist statistics begin to intersect in the limit of infinite sampling.\n",
    "\n",
    "### Multinomial and Dirichelet\n",
    "\n",
    "Consider the multinomial distribution (where each parameter $\\theta_{i}$ represents an equivalent positive outcome parameter for that variable $x_{k}$):\n",
    "\n",
    "$$p(x\\ |\\ \\theta) = \\theta_{1}^{x_{1}}\\theta_{2}^{x_{2}}\\theta_{3}^{x_{3}}\\ldots\\theta_{K}^{x_{K}}$$\n",
    "\n",
    "The conjugate prior is:\n",
    "\n",
    "$$p(\\theta\\ |\\ \\alpha) = K(\\alpha)\\theta_{1}^{\\alpha_{1}-1}\\theta_{2}^{\\alpha_{2}-1}\\theta_{3}^{\\alpha_{3}-1}\\ldots\\theta_{K}^{\\alpha_{K}-1}$$\n",
    "\n",
    "For $\\alpha_{i} > 0$ we can normalize this distribution by integration over the parameters such that $\\sum_{k=1}^{K}\\theta_{k} = 1$\n",
    "\n",
    "$$ K(\\alpha) = \\dfrac{\\Gamma(\\sum_{k=1}^{K}\\alpha_{k})}{\\Pi_{k=1}^{K}\\Gamma(\\alpha_{k})}$$\n",
    "\n",
    "This conjugate prior is the *Dirichelet* distribution and is extremely important (for example in Latent Dirichelet Allocation) in machine learning.\n",
    "\n",
    "The posterior predictive mean is:\n",
    "\n",
    "$$ E\\left[\\theta_{i}\\ |\\ {\\bf{x}}, \\alpha\\right] = \\dfrac{\\sum_{n=1}^{N}x_{n,i}+\\alpha_{i}}{N+\\alpha} $$\n",
    "\n",
    "\n",
    "### Poisson and Gamma\n",
    "\n",
    "Let's also consider the Poisson distribution:\n",
    "\n",
    "$$p(x\\ |\\ \\theta) = \\dfrac{\\theta^{x}e^{-\\theta}}{x!}$$\n",
    "\n",
    "With a corresponding conjugate prior\n",
    "\n",
    "$$p(\\theta\\ |\\ \\alpha) = K(\\alpha)\\theta^{\\alpha_{1}-1}e^{-\\alpha_{2}\\theta}$$\n",
    "\n",
    "With\n",
    "\n",
    "$$K(\\alpha) = \\dfrac{\\alpha_{2}^{\\alpha_{1}}}{\\Gamma(\\alpha_{1})}$$\n",
    "\n",
    "This prior is called the [Gamma](https://en.wikipedia.org/wiki/Gamma_distribution) distribution. It is not the same thing as the $\\Gamma$ function.\n",
    "\n",
    "The table presented [here](https://en.wikipedia.org/wiki/Conjugate_prior) provides a nice summary of commonly used conjugate priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP estimation \n",
    " \n",
    "You should already be familiar with maximum-likelihood (ML) estimation, based primarily on maximizing the value of the likelihood function. Therefore, we look for the value $\\hat{x}_{ML}$ that maximizes:\n",
    "\n",
    "$$f_{Y\\ |\\ X}(y\\ |\\ x)$$\n",
    "\n",
    "The Maximum A Posteriori (MAP) estimate of a variable X given Y = y is the value of x that maximizes the posterior PDF or PMF (continuous or discrete variables). We usually write this value as an estimator; where the MAP estimate of X is written $\\hat{x}_{MAP}$.\n",
    "\n",
    "To find the MAP estimate, we need to find the value of x that maximizes\n",
    "\n",
    "$$f_{X\\ |\\ Y}(x\\ |\\ y) = \\dfrac{f_{Y\\ |\\ X}(y\\ |\\ x)\\ f_{X}(x)}{f_{Y}(y)}$$\n",
    "\n",
    "(or substitute a discrete PMF in the case of discrete variables. \n",
    "\n",
    "** Protip:**\n",
    "\n",
    "Note that the value of x that maximizes the MAP estimate has no relationship with y. Hence we need not compute the value of $f_{Y}(y)$ explicitly, or even really involve it at all in the calculation of the MAP. Instead we can maximize:\n",
    "\n",
    "$$ f_{Y\\ |\\ X}(y\\ |\\ x)\\ f_{X}(x) $$\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Suppose X is a continuous random variable with the following PDF:\n",
    "\n",
    "$$f_{X}(x) = \\begin{cases}\n",
    "2x\\ \\ \\ \\ 0 \\leq x \\leq 1\\\\\n",
    "0\\ \\ \\ \\ \\ \\ \\text{otherwise}\n",
    "\\end{cases} $$\n",
    "\n",
    "Now suppose that $Y\\ |\\ X = x \\sim \\text{Geometric(x)}$. Now find the MAP estimate of X given Y = 3.\n",
    "\n",
    "**Protip: a very large number of real life data sets are in fact [geometric distributions](https://en.wikipedia.org/wiki/Geometric_distribution)** \n",
    "\n",
    "\n",
    "We are given the form of the likelihood:\n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ P_{Y\\ |\\ X}(y\\ |\\ x) = x(1-x)^{y-1}\\ \\ \\ \\  \\text{for}\\ \\  \\ \\ y = 1, 2, 3, \\cdots$\n",
    "\n",
    "Inserting our current value of $y$:\n",
    "\n",
    "$$P_{Y\\ |\\ X}(3\\ |\\ x) = x(1-x)^{2}$$\n",
    "\n",
    "Applying Bayes' theorem:\n",
    "\n",
    "$$P_{Y\\ |\\ X}(y\\ |\\ x)\\ f_{X}(x) = x(1-x)^{2} \\cdot 2x$$  \n",
    "\n",
    "$$P_{Y\\ |\\ X}(y\\ |\\ x)\\ f_{X}(x) = 2x^{2}(1-x)^{2}$$  \n",
    "\n",
    "We can find the maximizing value of x using differentiation:\n",
    "\n",
    "$$\\dfrac{d}{dx} 2x^{2}(1-x)^{2} = 4x(1-x)^{2} - 4x^{2}(1-x) = 0 $$\n",
    "\n",
    "And from this we can get an estimate of the MAP:\n",
    "\n",
    "$$4x(1-x)^{2} =  4x^{2}(1-x)$$\n",
    "\n",
    "$$(1-x)^{2} =  x(1-x)$$\n",
    "\n",
    "$$1 = \\dfrac{x}{(1-x)}$$\n",
    "\n",
    "$$x = \\dfrac{1}{2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of ML to MAP estimates:\n",
    "\n",
    "We are just going to provide a simple example here of the quintessential difference between these two estimates. \n",
    "\n",
    "#### Example:\n",
    "\n",
    "Suppose that we are transmitting a signal $X$ with a normal distribution with $\\mu = 0$ and variance $\\sigma_{X} \\neq 0$ (nevermind the detail about the contents) over a noisy communication channel where the noise $W$ has $\\mu = 0$ and variance $\\sigma_{W} \\neq 0$, independent of $X$.\n",
    "\n",
    "Assume that the recieved signal $Y$ consists of an additive relationship between $X$ and $W$ such that:\n",
    "\n",
    "$$Y = X + W$$\n",
    "\n",
    "1. Compute the ML estimate of $X$ given that $Y=y$ \n",
    "2. Compute the MLE estimate of $X$ given that $Y=y$\n",
    "\n",
    "(this is a somewhat simplified version of a real problem)\n",
    "\n",
    "**solution to part 1**\n",
    "\n",
    "We have \n",
    "\n",
    "$$f_{X}(x) = \\dfrac{1}{\\sqrt{2\\ \\pi}\\sigma_{X}}e^{-\\dfrac{x^{2}}{2\\ \\sigma_{X}^{2}}} $$\n",
    "\n",
    "In this case, for every piece of data $x$ we have gathered from the communications channel, we need to include the effect of the noise on changing the arrival value of the data point, thus every observation $X = x$ given an observation $Y = y$, will arrive within a normal variance of its original value, dependent on the variance in the noise term:\n",
    "\n",
    "$$f_{Y\\ |\\ X}(y\\ |\\ x) = \\dfrac{1}{\\sqrt{2\\ \\pi}\\sigma_{W}}e^{-\\dfrac{(y-x)^{2}}{2\\ \\sigma_{W}^{2}}} $$ \n",
    "\n",
    "To maximize the above function, we need to minimize the algebraic term $(y-x)^{2}$. Therefore, we can conclude:\n",
    "\n",
    "$$\\hat{x}_{ML} = y$$\n",
    "\n",
    "In otherwords, we are to implicitly believe that the most likely interpretation of the signal arriving at the other end is that it is accurate, regardless of the variance of the noise term, and indeed the relationship between the variance of the noise and the variance of the transmitted signal is not taken into account. (What does this mean to the scientist studying it?)\n",
    "\n",
    "**solution to part 2**\n",
    "\n",
    "Here we want to compute the MAP, so we are going to find the maximizer of \n",
    "\n",
    "$$f_{Y\\ |\\ X}(y\\ |\\ x)f_{X}(x) = \\dfrac{1}{\\sqrt{2\\ \\pi}\\sigma_{W}}e^{-\\dfrac{(y-x)^{2}}{2\\ \\sigma_{W}^{2}}}\\left[\\dfrac{1}{\\sqrt{2\\ \\pi}\\sigma_{X}}e^{-\\dfrac{x^{2}}{2\\ \\sigma_{X}^{2}}}\\right] $$\n",
    "\n",
    "$$f_{Y\\ |\\ X}(y\\ |\\ x)f_{X}(x) = \\dfrac{1}{2\\ \\pi\\ \\sigma_{W} \\sigma_{X}}e^{-\\left(\\dfrac{(y-x)^{2}}{2\\ \\sigma_{W}^{2}}+\\dfrac{x^{2}}{2\\ \\sigma_{X}^{2}}\\right)} $$\n",
    "\n",
    "Again, we need to minimize the exponential term:\n",
    "\n",
    "$$c = -\\left(\\dfrac{(y-x)^{2}}{2\\ \\sigma_{W}^{2}}+\\dfrac{x^{2}}{2\\ \\sigma_{X}^{2}}\\right)$$\n",
    "\n",
    "\n",
    "Differentiating against x, we find\n",
    "\n",
    "$$0 = -\\dfrac{(y-x)}{\\sigma_{W}^{2}}+\\dfrac{x}{\\sigma_{X}^{2}}$$\n",
    "\n",
    "$$\\dfrac{(y-x)}{\\sigma_{W}^{2}} = \\dfrac{x}{\\sigma_{X}^{2}}$$\n",
    "\n",
    "$$\\sigma_{X}^{2}(y-x) = x \\cdot \\sigma_{W}^{2} $$\n",
    "\n",
    "$$\\sigma_{X}^{2}y = x\\ \\sigma_{W}^{2}+x\\ \\sigma_{X}^{2}$$\n",
    "\n",
    "Factoring out the x, we get the following estimate:\n",
    "\n",
    "$$\\hat{x}_{MAP} = \\dfrac{\\sigma_{X}^{2}y}{\\sigma_{W}^{2}+\\sigma_{X}^{2}}$$\n",
    "\n",
    "As you can see, the MAP estimate definitely includes the effect of variance between the noise and base term. The variance of the base term plays an important part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MMSE (LSE) Estimate\n",
    "\n",
    "As an alternative to the MAP estimate, we might also consider the **MMSE estimate** if we are sufficiently far from converged sampling or that the distribution we are considering has a strange distribution with the MAP far from the bulk of the PDF.\n",
    "\n",
    "The minimum mean squared error estimate of the random variable X given an observed Y = y is given by:\n",
    "\n",
    "$$\\hat{x}_{M} = E\\left[X\\ |\\ Y=y\\right]$$\n",
    "\n",
    "#### Example\n",
    "\n",
    "Suppose X is a continuous random variable with the following PDF:\n",
    "\n",
    "$$f_{X}(x) = \\begin{cases}\n",
    "2x\\ \\ \\ \\ 0 \\leq x \\leq 1\\\\\n",
    "0\\ \\ \\ \\ \\ \\ \\text{otherwise}\n",
    "\\end{cases} $$\n",
    "\n",
    "$$f_{Y\\ |\\ X}(y\\ |\\ x) = \\begin{cases}\n",
    "2xy-x +1\\ \\ \\ \\ 0 \\leq y \\leq 1\\\\\n",
    "0\\ \\ \\ \\ \\ \\ \\text{otherwise}\n",
    "\\end{cases} $$\n",
    "\n",
    "Find the MMSE estimate of X, given that Y=y is observed.\n",
    "\n",
    "We need the posterior, \n",
    "\n",
    "$$f_{X\\ |\\ Y}(x\\ |\\ y) = \\dfrac{f_{Y\\ |\\ X}(y\\ |\\ x)f_{X}(x)}{f_{Y}(y)}$$\n",
    "\n",
    "$$f_{Y}(y) = \\int_{0}^{1}(2xy-x +1)2x\\ dx = \\dfrac{4}{3}y+\\dfrac{1}{3}, \\text{for}\\ 0 \\leq y \\leq 1$$\n",
    "\n",
    "$$f_{X\\ |\\ Y}(x\\ |\\ y) = \\dfrac{2x(2xy-x +1)}{\\dfrac{4}{3}y+\\dfrac{1}{3}} = \\dfrac{6x(2xy-x +1)}{4y+1}$$\n",
    "\n",
    "We compute the mean of the posterior to get the MMSE estimator:\n",
    "\n",
    "$$\\hat{x}_{M} = \\int_{0}^{1}xf_{X\\ |\\ Y}(x\\ |\\ y)dx$$\n",
    "\n",
    "$$ =\\dfrac{1}{4y+1}\\int_{0}^{1}6x^{2}(2xy-x+1)dx $$\n",
    "\n",
    "$$ =\\dfrac{3y+\\frac{1}{2}}{4y+1} $$\n",
    "\n",
    "#### Exercise:\n",
    "\n",
    "To be done on your own: How does this compare to the MAP estimate? The ML estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Main Terms and Points, 4.1 and 4.2:\n",
    "\n",
    "1. Meaning of Bayesian analysis\n",
    "2. Definition of Prior, Likelihood and Posterior\n",
    "3. Formulations of Bayes law and examples\n",
    "4. Bayesian updating\n",
    "5. Urn problems\n",
    "6. Outcome problems\n",
    "7. Credibility\n",
    "8. Conjugate priors - Beta/Bernoulli, Poisson/Gamma, Multinomial/Dirichelet\n",
    "9. Posterior predictives\n",
    "9. MAP estimation\n",
    "10. MMSE estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ad hoc pairs - define and present"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
